todo:
- посмотреть tokenkit, какие у него возможности, может сможет работать с большим количеством токенизаторов, чем штука от меты
- взять любую легкую модель, попытаться сконвертировать в битовый формат (напр, через токенкит, генлм, может еще какие-то способы оптимальные есть).
- накидать идеи, куда можно от этого двинуться, может можно придумать как делать конвершн в битовый формат чуть быстрее либо за счет построения КА элементами из токенизатора (BPE tokenizer).
- можно почитать про prefix trie / prefix array (проект infini-gram (https://infini-gram.io/)). возможно из нее можно имплементации для каверингов переиспользовать?

todo later:
- посмотреть, что получается, если смотрим на likelihood побитовых последовательностей.
- посмотреть в сторону алгоритмов на автоматах (каверинги от меты (https://github.com/facebookresearch/Exact-Byte-Level-Probabilities-from-Tokenized-LMs/tree/main))
- ансамблирование побитовых моделей, адверсариальные атаки против ансамбля моделей

глобально:
- первая цель: не эвристический выбор позиции. 
выбирать позиции для редактирования лучше, чем Charmer и по сути юзать это для ллмок, а не детерминированных энкодеров, но начать лучше с энкодеров (мы хотим не эвристически выбирать позицию, а использовать каверинги). 
посмотреть, могут ли помочь в выборе позиции всякие алгоритмы на автоматах (напр, карасика). надо рассмотреть разные подстроки. нужно сконвертировать модель в последовательность символов, за меньшее количество запросов сделать атаку.
- вторая цель: скорость работы. 
можем ли мы существенно ускорить чармер? (сразу работать с последовательностью битов, быстрее находить вещи, можно еще и хешировать). попытаться сделать это быстрее либо за счет хеширования, либо за счет алгоритмов частичного паттерн-матчинга.
